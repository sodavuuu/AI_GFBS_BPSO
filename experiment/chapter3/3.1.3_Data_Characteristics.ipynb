{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827ad9e0",
   "metadata": {},
   "source": [
    "# 3.1.3 DATA CHARACTERISTICS IMPACT ANALYSIS\n",
    "\n",
    "## Ph√¢n t√≠ch ·∫£nh h∆∞·ªüng c·ªßa ƒë·∫∑c ƒëi·ªÉm d·ªØ li·ªáu\n",
    "\n",
    "Notebook n√†y ph√¢n t√≠ch ·∫£nh h∆∞·ªüng c·ªßa c√°c ƒë·∫∑c ƒëi·ªÉm d·ªØ li·ªáu l√™n hi·ªáu su·∫•t thu·∫≠t to√°n:\n",
    "- **K√≠ch th∆∞·ªõc d·ªØ li·ªáu**: Small (30), Medium (50), Large (70) items\n",
    "- **ƒê·ªô t∆∞∆°ng quan**: Low correlation, High correlation, High value\n",
    "- **Ph√¢n b·ªë v√πng**: 1 region (ƒë·ªìng nh·∫•t), 2 regions, 3 regions (ƒëa d·∫°ng)\n",
    "- **Ph√¢n lo·∫°i**: Category (clothing, electronics, food, furniture)\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- X√°c ƒë·ªãnh ƒë·∫∑c ƒëi·ªÉm d·ªØ li·ªáu n√†o thu·∫≠n l·ª£i/b·∫•t l·ª£i cho t·ª´ng thu·∫≠t to√°n\n",
    "- ƒê√°nh gi√° ƒë·ªô nh·∫°y c·∫£m c·ªßa thu·∫≠t to√°n v·ªõi c√°c ƒë·∫∑c ƒëi·ªÉm kh√°c nhau\n",
    "- ƒê∆∞a ra khuy·∫øn ngh·ªã l·ª±a ch·ªçn thu·∫≠t to√°n ph√π h·ª£p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d80be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, '../../')\n",
    "from src.visualization import AdvancedKnapsackVisualizer\n",
    "\n",
    "# Create visualizer instance\n",
    "visualizer = AdvancedKnapsackVisualizer()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries and visualizer loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548d2f3",
   "metadata": {},
   "source": [
    "---\n",
    "## PH·∫¶N 1: LOAD V√Ä KH√ÅM PH√Å D·ªÆ LI·ªÜU\n",
    "\n",
    "### 1.1. Load Data Characteristics Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data characteristics analysis results\n",
    "df_data = pd.read_csv('../../results/chapter3/3_1_3_data_characteristics.csv')\n",
    "\n",
    "print(\"Data Characteristics Impact Analysis\")\n",
    "print(\"=\"*100)\n",
    "print(df_data.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Group by characteristic for analysis\n",
    "characteristics = df_data['characteristic'].unique()\n",
    "print(f\"\\nüìä Analyzed Characteristics: {list(characteristics)}\")\n",
    "print(f\"Total test cases: {len(df_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b8343",
   "metadata": {},
   "source": [
    "### 1.2. Summary Statistics by Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary PNG generated by experiments.py\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"\\nüìä Data Characteristics Impact Visualization:\")\n",
    "print(\"=\"*80)\n",
    "display(Image('../../results/chapter3/3_1_3_data_characteristics.png'))\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nSummary Table:\")\n",
    "print(df_data[['characteristic', 'test_case', 'gbfs_value', 'bpso_value', 'better_algorithm']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca963ae8",
   "metadata": {},
   "source": [
    "---\n",
    "## PH·∫¶N 2: VISUALIZATION - IMPACT OF DATA CHARACTERISTICS\n",
    "\n",
    "### 2.1. Quality Comparison by Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Quality comparison across characteristics\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "x = np.arange(len(df_data))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars\n",
    "bars1 = ax.bar(x - width/2, df_data['gbfs_pct_optimal'], width,\n",
    "               label='GBFS', color='#2ecc71', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "bars2 = ax.bar(x + width/2, df_data['bpso_pct_optimal'], width,\n",
    "               label='BPSO', color='#3498db', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(y=100, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Optimal (100%)')\n",
    "ax.axhline(y=95, color='orange', linestyle=':', linewidth=1.5, alpha=0.5, label='95% threshold')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_ylabel('% of Optimal Solution', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Algorithm Performance vs Data Characteristics\\n(Higher is Better)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([c.replace('_', ' ').title() for c in df_data['characteristic']],\n",
    "                    rotation=45, ha='right', fontsize=11)\n",
    "ax.legend(loc='lower right', fontsize=12)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim([50, 105])\n",
    "\n",
    "# Annotate BPSO low performers\n",
    "for i, (char, bpso_pct) in enumerate(zip(df_data['characteristic'], df_data['bpso_pct_optimal'])):\n",
    "    if bpso_pct < 65:\n",
    "        ax.annotate(f'{bpso_pct:.1f}%\\n‚ö†Ô∏è',\n",
    "                   xy=(i + width/2, bpso_pct),\n",
    "                   xytext=(0, -20),\n",
    "                   textcoords='offset points',\n",
    "                   ha='center', fontsize=9,\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', fc='yellow', alpha=0.7),\n",
    "                   arrowprops=dict(arrowstyle='->', lw=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Quality comparison visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad706e9e",
   "metadata": {},
   "source": [
    "### 2.2. Time Complexity by Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Execution time comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "x = np.arange(len(df_data))\n",
    "width = 0.25\n",
    "\n",
    "# Plot bars (in milliseconds)\n",
    "bars1 = ax.bar(x - width, df_data['gbfs_time']*1000, width,\n",
    "               label='GBFS', color='#2ecc71', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "bars2 = ax.bar(x, df_data['bpso_time']*1000, width,\n",
    "               label='BPSO', color='#3498db', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "bars3 = ax.bar(x + width, df_data['dp_time']*1000, width,\n",
    "               label='DP', color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_ylabel('Execution Time (ms, log scale)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Computational Cost vs Data Characteristics\\n(Lower is Better)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([c.replace('_', ' ').title() for c in df_data['characteristic']],\n",
    "                    rotation=45, ha='right', fontsize=11)\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='upper left', fontsize=12)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add 1ms reference line\n",
    "ax.axhline(y=1, color='purple', linestyle=':', linewidth=1.5, alpha=0.5, label='1ms threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Time complexity visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0942e0",
   "metadata": {},
   "source": [
    "### 2.3. Quality-Time Trade-off Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391faddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Quality vs Time scatter by characteristic\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Color map for characteristics\n",
    "char_colors = {\n",
    "    'low_correlation': '#FF6B6B',\n",
    "    'high_correlation': '#4ECDC4',\n",
    "    'high_value': '#45B7D1',\n",
    "    'region_1': '#96CEB4',\n",
    "    'region_3': '#FFEAA7'\n",
    "}\n",
    "\n",
    "# Plot each characteristic\n",
    "for char in df_data['characteristic'].unique():\n",
    "    subset = df_data[df_data['characteristic'] == char]\n",
    "    \n",
    "    # GBFS\n",
    "    ax.scatter(subset['gbfs_time']*1000, subset['gbfs_pct_optimal'],\n",
    "              s=300, alpha=0.7, marker='o', edgecolors='black', linewidth=2,\n",
    "              color=char_colors.get(char, '#95a5a6'),\n",
    "              label=f'{char.replace(\"_\", \" \").title()} - GBFS')\n",
    "    \n",
    "    # BPSO\n",
    "    ax.scatter(subset['bpso_time']*1000, subset['bpso_pct_optimal'],\n",
    "              s=300, alpha=0.5, marker='s', edgecolors='black', linewidth=2,\n",
    "              color=char_colors.get(char, '#95a5a6'))\n",
    "    \n",
    "    # Connect GBFS and BPSO for same characteristic\n",
    "    ax.plot([subset['gbfs_time'].iloc[0]*1000, subset['bpso_time'].iloc[0]*1000],\n",
    "           [subset['gbfs_pct_optimal'].iloc[0], subset['bpso_pct_optimal'].iloc[0]],\n",
    "           'k--', alpha=0.3, linewidth=1.5)\n",
    "    \n",
    "    # Annotate characteristic name\n",
    "    ax.annotate(char.replace('_', ' ').title(),\n",
    "               xy=(subset['gbfs_time'].iloc[0]*1000, subset['gbfs_pct_optimal'].iloc[0]),\n",
    "               xytext=(10, 10), textcoords='offset points',\n",
    "               fontsize=9, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round,pad=0.4', fc='white', alpha=0.8))\n",
    "\n",
    "# Reference regions\n",
    "ax.axhline(y=95, color='orange', linestyle=':', linewidth=2, alpha=0.5)\n",
    "ax.axvline(x=1, color='purple', linestyle=':', linewidth=2, alpha=0.5)\n",
    "\n",
    "# \"Sweet spot\" region\n",
    "from matplotlib.patches import Rectangle\n",
    "sweet_spot = Rectangle((0.005, 95), 1, 10, facecolor='green', alpha=0.1, edgecolor='green',\n",
    "                       linewidth=2, linestyle='--')\n",
    "ax.add_patch(sweet_spot)\n",
    "ax.text(0.05, 100, 'IDEAL\\nREGION', fontsize=11, fontweight='bold',\n",
    "       color='green', alpha=0.7, ha='center', va='center')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_xlabel('Execution Time (ms, log scale)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('% of Optimal Solution', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Quality vs Speed Trade-off by Data Characteristic\\n(Top-Left is Best)',\n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim([0.005, 30])\n",
    "ax.set_ylim([55, 105])\n",
    "ax.legend(loc='lower right', fontsize=9, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Quality vs Time scatter plot complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921f9b0",
   "metadata": {},
   "source": [
    "---\n",
    "## PH·∫¶N 3: PH√ÇN T√çCH CHI TI·∫æT T·ª™NG ƒê·∫∂C ƒêI·ªÇM\n",
    "\n",
    "### 3.1. Low vs High Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca49fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare low vs high correlation\n",
    "low_corr = df_data[df_data['characteristic'] == 'low_correlation'].iloc[0]\n",
    "high_corr = df_data[df_data['characteristic'] == 'high_correlation'].iloc[0]\n",
    "\n",
    "print(\"\\nüìä CORRELATION IMPACT ANALYSIS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nLOW CORRELATION (Value v√† Weight ƒë·ªôc l·∫≠p):\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  Test Case: {low_corr['test_case']}\")\n",
    "print(f\"  GBFS: {low_corr['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  BPSO: {low_corr['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Gap:  {low_corr['gbfs_pct_optimal'] - low_corr['bpso_pct_optimal']:.2f}%\")\n",
    "\n",
    "print(\"\\nHIGH CORRELATION (Value t·ª∑ l·ªá v·ªõi Weight):\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  Test Case: {high_corr['test_case']}\")\n",
    "print(f\"  GBFS: {high_corr['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  BPSO: {high_corr['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Gap:  {high_corr['gbfs_pct_optimal'] - high_corr['bpso_pct_optimal']:.2f}%\")\n",
    "\n",
    "print(\"\\nüîç INSIGHTS:\")\n",
    "print(\"-\" * 100)\n",
    "if low_corr['gbfs_pct_optimal'] > high_corr['gbfs_pct_optimal']:\n",
    "    print(\"  ‚úÖ GBFS performs BETTER on LOW correlation data\")\n",
    "    print(\"     ‚Üí Greedy by ratio works well when value/weight ratios are diverse\")\n",
    "else:\n",
    "    print(\"  ‚úÖ GBFS performs BETTER on HIGH correlation data\")\n",
    "    print(\"     ‚Üí Greedy by ratio is optimal when value proportional to weight\")\n",
    "\n",
    "if low_corr['bpso_pct_optimal'] < high_corr['bpso_pct_optimal']:\n",
    "    print(\"  ‚ö†Ô∏è BPSO struggles MORE on LOW correlation data\")\n",
    "    print(\"     ‚Üí Harder to explore when no clear pattern\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è BPSO struggles MORE on HIGH correlation data\")\n",
    "    print(\"     ‚Üí May get trapped in local optima\")\n",
    "\n",
    "print(f\"\\n  üìä Performance gap: {abs(low_corr['gbfs_pct_optimal'] - low_corr['bpso_pct_optimal']):.1f}% (Low) vs \"\n",
    "      f\"{abs(high_corr['gbfs_pct_optimal'] - high_corr['bpso_pct_optimal']):.1f}% (High)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332d9df",
   "metadata": {},
   "source": [
    "### 3.2. High Value vs Normal Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d45777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze high value impact\n",
    "high_val = df_data[df_data['characteristic'] == 'high_value'].iloc[0]\n",
    "\n",
    "print(\"\\nüìä HIGH VALUE ITEMS IMPACT:\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nTest Case: {high_val['test_case']}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  GBFS: {high_val['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  BPSO: {high_val['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Gap:  {high_val['gbfs_pct_optimal'] - high_val['bpso_pct_optimal']:.2f}%\")\n",
    "\n",
    "print(\"\\nüîç INSIGHTS:\")\n",
    "print(\"-\" * 100)\n",
    "if high_val['bpso_pct_optimal'] > 75:\n",
    "    print(\"  ‚úÖ BPSO performs RELATIVELY WELL on high-value items\")\n",
    "    print(\"     ‚Üí Clear value signals help guide particle swarm\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è BPSO still STRUGGLES even with high-value items\")\n",
    "    print(\"     ‚Üí Greedy heuristic too strong to beat\")\n",
    "\n",
    "if high_val['gbfs_pct_optimal'] > 98:\n",
    "    print(\"  ‚úÖ GBFS nearly OPTIMAL on high-value items\")\n",
    "    print(\"     ‚Üí Value/weight ratio correctly identifies best items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b5665",
   "metadata": {},
   "source": [
    "### 3.3. Regional Diversity (1 Region vs 3 Regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare regional diversity\n",
    "region1 = df_data[df_data['characteristic'] == 'region_1'].iloc[0]\n",
    "region3 = df_data[df_data['characteristic'] == 'region_3'].iloc[0]\n",
    "\n",
    "print(\"\\nüìä REGIONAL DIVERSITY IMPACT:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1 REGION (Homogeneous):\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  Test Case: {region1['test_case']}\")\n",
    "print(f\"  GBFS: {region1['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  BPSO: {region1['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Gap:  {region1['gbfs_pct_optimal'] - region1['bpso_pct_optimal']:.2f}%\")\n",
    "\n",
    "print(\"\\n3 REGIONS (Diverse):\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  Test Case: {region3['test_case']}\")\n",
    "print(f\"  GBFS: {region3['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  BPSO: {region3['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Gap:  {region3['gbfs_pct_optimal'] - region3['bpso_pct_optimal']:.2f}%\")\n",
    "\n",
    "print(\"\\nüîç INSIGHTS:\")\n",
    "print(\"-\" * 100)\n",
    "if region3['gbfs_pct_optimal'] > region1['gbfs_pct_optimal']:\n",
    "    print(\"  ‚úÖ GBFS handles regional DIVERSITY better\")\n",
    "else:\n",
    "    print(\"  üìä GBFS performance CONSISTENT regardless of diversity\")\n",
    "    print(\"     ‚Üí Greedy heuristic not affected by regional characteristics\")\n",
    "\n",
    "if region3['bpso_pct_optimal'] > region1['bpso_pct_optimal']:\n",
    "    print(\"  ‚úÖ BPSO improves with regional DIVERSITY\")\n",
    "    print(\"     ‚Üí More diverse search space helps exploration\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è BPSO struggles MORE with regional DIVERSITY\")\n",
    "    print(\"     ‚Üí Complexity increases, harder to converge\")\n",
    "\n",
    "print(f\"\\n  üìä Diversity impact on gap: {abs(region1['gbfs_pct_optimal'] - region1['bpso_pct_optimal']):.1f}% (1 region) vs \"\n",
    "      f\"{abs(region3['gbfs_pct_optimal'] - region3['bpso_pct_optimal']):.1f}% (3 regions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af29df",
   "metadata": {},
   "source": [
    "---\n",
    "## PH·∫¶N 4: RANKINGS V√Ä KHUY·∫æN NGH·ªä\n",
    "\n",
    "### 4.1. Best/Worst Case Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ff883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best and worst cases for each algorithm\n",
    "print(\"\\nüèÜ BEST & WORST CASE SCENARIOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# GBFS\n",
    "gbfs_best = df_data.loc[df_data['gbfs_pct_optimal'].idxmax()]\n",
    "gbfs_worst = df_data.loc[df_data['gbfs_pct_optimal'].idxmin()]\n",
    "\n",
    "print(\"\\nGBFS:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  ‚úÖ BEST:  {gbfs_best['characteristic'].replace('_', ' ').title()} - \"\n",
    "      f\"{gbfs_best['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  ‚ö†Ô∏è WORST: {gbfs_worst['characteristic'].replace('_', ' ').title()} - \"\n",
    "      f\"{gbfs_worst['gbfs_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Range: {gbfs_best['gbfs_pct_optimal'] - gbfs_worst['gbfs_pct_optimal']:.2f}%\")\n",
    "\n",
    "# BPSO\n",
    "bpso_best = df_data.loc[df_data['bpso_pct_optimal'].idxmax()]\n",
    "bpso_worst = df_data.loc[df_data['bpso_pct_optimal'].idxmin()]\n",
    "\n",
    "print(\"\\nBPSO:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  ‚úÖ BEST:  {bpso_best['characteristic'].replace('_', ' ').title()} - \"\n",
    "      f\"{bpso_best['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  ‚ö†Ô∏è WORST: {bpso_worst['characteristic'].replace('_', ' ').title()} - \"\n",
    "      f\"{bpso_worst['bpso_pct_optimal']:.2f}% optimal\")\n",
    "print(f\"  Range: {bpso_best['bpso_pct_optimal'] - bpso_worst['bpso_pct_optimal']:.2f}%\")\n",
    "\n",
    "print(\"\\nüîç KEY FINDINGS:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"  ‚Ä¢ GBFS is VERY STABLE across characteristics (range: {gbfs_best['gbfs_pct_optimal'] - gbfs_worst['gbfs_pct_optimal']:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ BPSO is HIGHLY VARIABLE across characteristics (range: {bpso_best['bpso_pct_optimal'] - bpso_worst['bpso_pct_optimal']:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ GBFS consistently outperforms BPSO by {df_data['gbfs_pct_optimal'].mean() - df_data['bpso_pct_optimal'].mean():.1f}% on average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd5703",
   "metadata": {},
   "source": [
    "### 4.2. Recommendations by Data Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "print(\"\\nüí° ALGORITHM RECOMMENDATIONS BY DATA CHARACTERISTIC:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for _, row in df_data.iterrows():\n",
    "    char = row['characteristic'].replace('_', ' ').title()\n",
    "    print(f\"\\n{char}:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Determine recommendation\n",
    "    if row['gbfs_pct_optimal'] >= 99:\n",
    "        print(f\"  ü•á STRONGLY RECOMMEND: GBFS ({row['gbfs_pct_optimal']:.2f}% optimal, {row['gbfs_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Excellent quality, extremely fast\")\n",
    "    elif row['gbfs_pct_optimal'] >= 95:\n",
    "        print(f\"  ü•á RECOMMEND: GBFS ({row['gbfs_pct_optimal']:.2f}% optimal, {row['gbfs_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Very good quality, extremely fast\")\n",
    "    else:\n",
    "        print(f\"  ü•à CONSIDER: GBFS ({row['gbfs_pct_optimal']:.2f}% optimal, {row['gbfs_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Good quality, extremely fast\")\n",
    "    \n",
    "    if row['bpso_pct_optimal'] >= 70:\n",
    "        print(f\"  ü•â ALTERNATIVE: BPSO ({row['bpso_pct_optimal']:.2f}% optimal, {row['bpso_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Acceptable if complex constraints exist\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå AVOID: BPSO ({row['bpso_pct_optimal']:.2f}% optimal, {row['bpso_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Poor quality, not worth the computational cost\")\n",
    "    \n",
    "    # DP recommendation\n",
    "    if row['dp_time'] < 0.02:  # < 20ms\n",
    "        print(f\"  üíé OPTIMAL: DP (100% optimal, {row['dp_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Use if guarantee optimal is required and time acceptable\")\n",
    "    else:\n",
    "        print(f\"  ‚è±Ô∏è BASELINE: DP (100% optimal, {row['dp_time']*1000:.4f}ms)\")\n",
    "        print(f\"     ‚Üí Use only for validation or when absolute optimality needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d28464",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù K·∫æT LU·∫¨N\n",
    "\n",
    "### T·ªïng k·∫øt ph√¢n t√≠ch ·∫£nh h∆∞·ªüng ƒë·∫∑c ƒëi·ªÉm d·ªØ li·ªáu:\n",
    "\n",
    "#### üéØ Ph√°t hi·ªán ch√≠nh:\n",
    "\n",
    "1. **GBFS Consistency** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "   - Performance r·∫•t ·ªïn ƒë·ªãnh tr√™n M·ªåI ƒë·∫∑c ƒëi·ªÉm d·ªØ li·ªáu\n",
    "   - Lu√¥n ƒë·∫°t >97% optimal b·∫•t k·ªÉ correlation, value distribution, ho·∫∑c diversity\n",
    "   - Kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi complexity c·ªßa data\n",
    "   - **Conclusion**: GBFS l√† \"universal solver\" cho Knapsack\n",
    "\n",
    "2. **BPSO Variability** ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "   - Performance dao ƒë·ªông M·∫†N H t·ª´ 57% ƒë·∫øn 77% optimal\n",
    "   - B·ªã ·∫£nh h∆∞·ªüng NHI·ªÄU b·ªüi data characteristics\n",
    "   - Kh√¥ng d·ª± ƒëo√°n ƒë∆∞·ª£c performance tr√™n data m·ªõi\n",
    "   - **Conclusion**: BPSO kh√¥ng ƒë√°ng tin c·∫≠y cho production\n",
    "\n",
    "3. **Correlation Impact**:\n",
    "   - GBFS ho·∫°t ƒë·ªông t·ªët v·ªõi c·∫£ low v√† high correlation\n",
    "   - BPSO struggle h∆°n v·ªõi low correlation (harder to find pattern)\n",
    "   - Value/weight ratio l√† heuristic ROBUST\n",
    "\n",
    "4. **Value Distribution Impact**:\n",
    "   - High-value items: C·∫£ GBFS v√† BPSO ƒë·ªÅu improve\n",
    "   - GBFS v·∫´n maintain >98% optimal\n",
    "   - BPSO improve nh∆∞ng v·∫´n << GBFS\n",
    "\n",
    "5. **Diversity Impact**:\n",
    "   - Regional/Category diversity: Kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn GBFS\n",
    "   - BPSO slightly worse v·ªõi diversity cao (complexity tƒÉng)\n",
    "   - GBFS's greedy heuristic kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi domain knowledge\n",
    "\n",
    "#### üìä Performance Summary:\n",
    "\n",
    "| Characteristic | GBFS % Opt | BPSO % Opt | Winner | Gap |\n",
    "|----------------|-----------|-----------|--------|-----|\n",
    "| Low Correlation | 98.8% | 65.7% | GBFS | 33.1% |\n",
    "| High Correlation | 98.9% | 57.5% | GBFS | 41.4% |\n",
    "| High Value | 98.7% | 76.8% | GBFS | 21.9% |\n",
    "| 1 Region | 99.3% | 59.7% | GBFS | 39.6% |\n",
    "| 3 Regions | 99.9% | 61.9% | GBFS | 38.0% |\n",
    "| **Average** | **99.1%** | **64.3%** | **GBFS** | **34.8%** |\n",
    "\n",
    "#### üéì Khuy·∫øn ngh·ªã cu·ªëi c√πng:\n",
    "\n",
    "**1. Default Choice: GBFS** ü•á\n",
    "- D√πng cho M·ªåI lo·∫°i Knapsack data\n",
    "- Kh√¥ng c·∫ßn analyze data characteristics tr∆∞·ªõc\n",
    "- Guaranteed >97% optimal, extremely fast\n",
    "\n",
    "**2. When to Use DP:** üíé\n",
    "- Khi NEED guarantee 100% optimal\n",
    "- n < 100 v√† W kh√¥ng qu√° l·ªõn\n",
    "- Validation v√† benchmarking\n",
    "\n",
    "**3. When to AVOID BPSO:** ‚ùå\n",
    "- Knapsack problem c∆° b·∫£n ‚Üí GBFS t·ªët h∆°n\n",
    "- C·∫ßn stability v√† predictability\n",
    "- Limited computational budget\n",
    "\n",
    "**4. When to Consider BPSO:** ü§î\n",
    "- Ch·ªâ khi c√≥ r√†ng bu·ªôc ph·ª©c t·∫°p (multi-dimensional, conflicts, dependencies)\n",
    "- GBFS kh√¥ng th·ªÉ handle\n",
    "- C√≥ th·ªùi gian tune parameters\n",
    "- Ch·∫•p nh·∫≠n run multiple times\n",
    "\n",
    "#### üöÄ Key Takeaway:\n",
    "\n",
    "> **\"Data characteristics DO NOT significantly impact algorithm choice for Knapsack problem. GBFS dominates across ALL data types. Choose algorithm based on CONSTRAINTS, not data characteristics.\"**\n",
    "\n",
    "### Next Steps:\n",
    "- Optimization: Combine parameters v√† data insights (4. Optimization.ipynb)\n",
    "- Enhancement: Develop hybrid or adaptive algorithms (5. EnhancedAlgorithm.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
